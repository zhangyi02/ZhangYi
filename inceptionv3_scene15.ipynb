{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionv3_scene15.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/zhangyi02/ZhangYi/blob/master/inceptionv3_scene15.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "B-tV3V4rPj89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e7a81b43-5b18-4813-df8b-a8cfe9058f28"
      },
      "cell_type": "code",
      "source": [
        "! wget http://www-cvr.ai.uiuc.edu/ponce_grp/data/scene_categories/scene_categories.zip\n",
        "! wget https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\n",
        "import zipfile\n",
        "import os\n",
        "def un_zip1():\n",
        "    \"\"\"unzip zip file\"\"\"\n",
        "    zip_file = zipfile.ZipFile(\"inception_dec_2015.zip\")\n",
        "    if os.path.isdir(\"inception_dec_2015\"):\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir(\"inception_dec_2015\")\n",
        "    for names in zip_file.namelist():\n",
        "        zip_file.extract(names,\"inception_dec_2015\")\n",
        "    zip_file.close()\n",
        "def un_zip2():\n",
        "    \"\"\"unzip zip file\"\"\"\n",
        "    zip_file = zipfile.ZipFile(\"scene_categories.zip\")\n",
        "    if os.path.isdir(\"scene_categories\"):\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir(\"scene_categories\")\n",
        "    for names in zip_file.namelist():\n",
        "        zip_file.extract(names,\"scene_categories\")\n",
        "    zip_file.close()    \n",
        "un_zip1()\n",
        "un_zip2()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-24 09:36:15--  http://www-cvr.ai.uiuc.edu/ponce_grp/data/scene_categories/scene_categories.zip\n",
            "Resolving www-cvr.ai.uiuc.edu (www-cvr.ai.uiuc.edu)... 128.174.227.253\n",
            "Connecting to www-cvr.ai.uiuc.edu (www-cvr.ai.uiuc.edu)|128.174.227.253|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86098604 (82M) [application/zip]\n",
            "Saving to: ‘scene_categories.zip.2’\n",
            "\n",
            "scene_categories.zi 100%[===================>]  82.11M  32.0MB/s    in 2.6s    \n",
            "\n",
            "2018-07-24 09:36:18 (32.0 MB/s) - ‘scene_categories.zip.2’ saved [86098604/86098604]\n",
            "\n",
            "--2018-07-24 09:36:19--  https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.28.128, 2607:f8b0:400e:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.28.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88631107 (85M) [application/zip]\n",
            "Saving to: ‘inception_dec_2015.zip.2’\n",
            "\n",
            "inception_dec_2015. 100%[===================>]  84.52M  96.2MB/s    in 0.9s    \n",
            "\n",
            "2018-07-24 09:36:20 (96.2 MB/s) - ‘inception_dec_2015.zip.2’ saved [88631107/88631107]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NCNwotyIQk2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce93f004-c929-4b37-f004-c25fcbb90ee9"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DC6vPNucVyRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d7138883-84e0-44ac-a070-e763fd32356c"
      },
      "cell_type": "code",
      "source": [
        "#   Data\n",
        "model_dir = './inception_dec_2015'\n",
        "model_file = 'tensorflow_inception_graph.pb'\n",
        "# os.mkdir(\"cache\")\n",
        "cache_dir = './cache'\n",
        "input_data = './scene_categories'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\t\t    inception_dec_2015.zip  scene_categories.zip\r\n",
            "inception_dec_2015  scene_categories\n",
            "datalab\t\t    inception_dec_2015.zip  scene_categories.zip\n",
            "inception_dec_2015  scene_categories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gqbCx_J5QrEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "069fe1d1-8301-407f-b917-ebc6c0e35961"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os.path\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.platform import gfile\n",
        "import pdb\n",
        "\n",
        "#   Data\n",
        "model_dir = './inception_dec_2015'\n",
        "model_file = 'tensorflow_inception_graph.pb'\n",
        "# os.mkdir(\"cache\")\n",
        "cache_dir = './cache'\n",
        "input_data = './scene_categories'\n",
        "\n",
        "# validation_percentage = 10\n",
        "# test_percentage = 10\n",
        "\n",
        "#   Model\n",
        "bottleneck_tensor_size = 2048\n",
        "bottleneck_tensor_name = 'pool_3/_reshape:0'\n",
        "jpeg_data_tensor_name = 'DecodeJpeg/contents:0'\n",
        "\n",
        "#   Parameters\n",
        "learning_rate = 0.01\n",
        "steps = 1000\n",
        "batch = 100\n",
        "checkpoint_every = 100\n",
        "num_checkpoints = 5\n",
        "\n",
        "# 从数据文件夹中读取所有的图片列表并按训练、验证、测试分开\n",
        "def create_image_lists():\n",
        "    result = {}  # 保存所有图像。key为类别名称。value也是字典，存储了所有的图片名称\n",
        "    sub_dirs = [x[0] for x in os.walk(input_data)]  # 获取所有子目录\n",
        "    is_root_dir = True  # 第一个目录为当前目录，需要忽略\n",
        "\n",
        "    # 分别对每个子目录进行操作\n",
        "    for sub_dir in sub_dirs:\n",
        "        if is_root_dir:\n",
        "            is_root_dir = False\n",
        "            continue\n",
        "\n",
        "        # 获取当前目录下的所有有效图片\n",
        "        extensions = {'jpg', 'jpeg', 'JPG', 'JPEG'}\n",
        "        file_list = []  # 存储所有图像\n",
        "        dir_name = os.path.basename(sub_dir)  # 获取路径的最后一个目录名字\n",
        "        for extension in extensions:\n",
        "            file_glob = os.path.join(input_data, dir_name, '*.' + extension)\n",
        "            file_list.extend(glob.glob(file_glob))\n",
        "        if not file_list:\n",
        "            continue\n",
        "\n",
        "        # 将当前类别的图片随机分为训练数据集、测试数据集、验证数据集\n",
        "        label_name = dir_name.lower()  # 通过目录名获取类别的名称\n",
        "        # training_images = []\n",
        "        # testing_images = []\n",
        "        # validation_images = []\n",
        "        training_images = random.sample(file_list, 100)\n",
        "        for i in range(100):\n",
        "            training_images[i] = os.path.basename(training_images[i])\n",
        "        rest = list(set(file_list) - set(training_images))\n",
        "        validation_images = random.sample(rest, 100)\n",
        "        for i in range(100):\n",
        "            validation_images[i] = os.path.basename(validation_images[i])\n",
        "        testing_images = list(set(rest) - set(training_images))\n",
        "        for i in range(len(testing_images)):\n",
        "            testing_images[i] = os.path.basename(testing_images[i])\n",
        "        # for file_name in file_list:\n",
        "        #     base_name = os.path.basename(file_name)  # 获取该图片的名称\n",
        "        #     pdb.set_trace()\n",
        "        #     chance = np.random.randint(100)  # 随机产生100个数代表百分比\n",
        "        #     if chance < validation_percentage:\n",
        "        #         validation_images.append(base_name)\n",
        "        #     elif chance < (validation_percentage + test_percentage):\n",
        "        #         testing_images.append(base_name)\n",
        "        #     else:\n",
        "        #         training_images.append(base_name)\n",
        "\n",
        "        # 将当前类别的数据集放入结果字典\n",
        "        result[label_name] = {\n",
        "            'dir': dir_name,\n",
        "            'training': training_images,\n",
        "            'testing': testing_images,\n",
        "            'validation': validation_images\n",
        "        }\n",
        "\n",
        "    # 返回整理好的所有数据\n",
        "    return result\n",
        "\n",
        "\n",
        "# 通过类别名称、所属数据集、图片编号获取一张图片的地址\n",
        "def get_image_path(image_lists, image_dir, label_name, index, category):\n",
        "    label_lists = image_lists[label_name]  # 获取给定类别中的所有图片\n",
        "    category_list = label_lists[category]  # 根据所属数据集的名称获取该集合中的全部图片\n",
        "    mod_index = index % len(category_list)  # 规范图片的索引\n",
        "    base_name = category_list[mod_index]  # 获取图片的文件名\n",
        "    sub_dir = label_lists['dir']  # 获取当前类别的目录名\n",
        "    full_path = os.path.join(image_dir, sub_dir, base_name)  # 图片的绝对路径\n",
        "    return full_path\n",
        "\n",
        "\n",
        "# 通过类别名称、所属数据集、图片编号获取特征向量值的地址\n",
        "def get_bottleneck_path(image_lists, label_name, index, category):\n",
        "    return get_image_path(image_lists, cache_dir, label_name, index,\n",
        "                          category) + '.txt'\n",
        "\n",
        "\n",
        "# 使用inception-v3处理图片获取特征向量\n",
        "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\n",
        "                            bottleneck_tensor):\n",
        "    bottleneck_values = sess.run(bottleneck_tensor,\n",
        "                                 {image_data_tensor: image_data})\n",
        "    bottleneck_values = np.squeeze(bottleneck_values)  # 将四维数组压缩成一维数组\n",
        "    return bottleneck_values\n",
        "\n",
        "\n",
        "# 获取一张图片经过inception-v3模型处理后的特征向量\n",
        "def get_or_create_bottleneck(sess, image_lists, label_name, index, category,\n",
        "                             jpeg_data_tensor, bottleneck_tensor):\n",
        "    # 获取一张图片对应的特征向量文件的路径\n",
        "    label_lists = image_lists[label_name]\n",
        "    sub_dir = label_lists['dir']\n",
        "    sub_dir_path = os.path.join(cache_dir, sub_dir)\n",
        "    if not os.path.exists(sub_dir_path):\n",
        "        os.makedirs(sub_dir_path)\n",
        "    bottleneck_path = get_bottleneck_path(image_lists, label_name, index,\n",
        "                                          category)\n",
        "\n",
        "    # 如果该特征向量文件不存在，则通过inception-v3模型计算并保存\n",
        "    if not os.path.exists(bottleneck_path):\n",
        "        image_path = get_image_path(image_lists, input_data, label_name, index,\n",
        "                                    category)  # 获取图片原始路径\n",
        "        image_data = gfile.FastGFile(image_path, 'rb').read()  # 获取图片内容\n",
        "        bottleneck_values = run_bottleneck_on_image(\n",
        "            sess, image_data, jpeg_data_tensor,\n",
        "            bottleneck_tensor)  # 通过inception-v3计算特征向量\n",
        "\n",
        "        # 将特征向量存入文件\n",
        "        bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
        "        with open(bottleneck_path, 'w') as bottleneck_file:\n",
        "            bottleneck_file.write(bottleneck_string)\n",
        "    else:\n",
        "        # 否则直接从文件中获取图片的特征向量\n",
        "        with open(bottleneck_path, 'r') as bottleneck_file:\n",
        "            bottleneck_string = bottleneck_file.read()\n",
        "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
        "\n",
        "    # 返回得到的特征向量\n",
        "    return bottleneck_values\n",
        "\n",
        "\n",
        "# 随机获取一个batch图片作为训练数据\n",
        "def get_random_cached_bottlenecks(sess, n_classes, image_lists, how_many,\n",
        "                                  category, jpeg_data_tensor,\n",
        "                                  bottleneck_tensor):\n",
        "    bottlenecks = []\n",
        "    ground_truths = []\n",
        "    for _ in range(how_many):\n",
        "        # 随机一个类别和图片编号加入当前的训练数据\n",
        "        label_index = random.randrange(n_classes)\n",
        "        label_name = list(image_lists.keys())[label_index]\n",
        "        image_index = random.randrange(65535)\n",
        "        bottleneck = get_or_create_bottleneck(\n",
        "            sess, image_lists, label_name, image_index, category,\n",
        "            jpeg_data_tensor, bottleneck_tensor)\n",
        "        ground_truth = np.zeros(n_classes, dtype=np.float32)\n",
        "        ground_truth[label_index] = 1.0\n",
        "        bottlenecks.append(bottleneck)\n",
        "        ground_truths.append(ground_truth)\n",
        "    return bottlenecks, ground_truths\n",
        "\n",
        "\n",
        "# 获取全部的测试数据\n",
        "def get_test_bottlenecks(sess, image_lists, n_classes, jpeg_data_tensor,\n",
        "                         bottleneck_tensor):\n",
        "    bottlenecks = []\n",
        "    ground_truths = []\n",
        "    label_name_list = list(image_lists.keys())\n",
        "    # 枚举所有的类别和每个类别中的测试图片\n",
        "    for label_index, label_name in enumerate(label_name_list):\n",
        "        category = 'testing'\n",
        "        for index, unused_base_name in enumerate(\n",
        "                image_lists[label_name][category]):\n",
        "            bottleneck = get_or_create_bottleneck(\n",
        "                sess, image_lists, label_name, index, category,\n",
        "                jpeg_data_tensor, bottleneck_tensor)\n",
        "            ground_truth = np.zeros(n_classes, dtype=np.float32)\n",
        "            ground_truth[label_index] = 1.0\n",
        "            bottlenecks.append(bottleneck)\n",
        "            ground_truths.append(ground_truth)\n",
        "    return bottlenecks, ground_truths\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    # 读取所有的图片\n",
        "    image_lists = create_image_lists()\n",
        "    n_classes = len(image_lists.keys())\n",
        "\n",
        "    with tf.Graph().as_default() as graph:\n",
        "        # 读取训练好的inception-v3模型\n",
        "        with gfile.FastGFile(os.path.join(model_dir, model_file), 'rb') as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            # 加载inception-v3模型，并返回数据输入张量和瓶颈层输出张量\n",
        "            bottleneck_tensor, jpeg_data_tensor = tf.import_graph_def(\n",
        "                graph_def,\n",
        "                return_elements=[bottleneck_tensor_name, jpeg_data_tensor_name])\n",
        "\n",
        "        # 定义新的神经网络输入\n",
        "        bottleneck_input = tf.placeholder(\n",
        "            tf.float32, [None, bottleneck_tensor_size],\n",
        "            name='BottleneckInputPlaceholder')\n",
        "\n",
        "        # 定义新的标准答案输入\n",
        "        ground_truth_input = tf.placeholder(\n",
        "            tf.float32, [None, n_classes], name='GroundTruthInput')\n",
        "\n",
        "        # 定义一层全连接层解决新的图片分类问题\n",
        "        with tf.name_scope('final_training_ops'):\n",
        "            weights = tf.Variable(\n",
        "                tf.truncated_normal(\n",
        "                    [bottleneck_tensor_size, n_classes], stddev=0.1))\n",
        "            biases = tf.Variable(tf.zeros([n_classes]))\n",
        "            logits = tf.matmul(bottleneck_input, weights) + biases\n",
        "            final_tensor = tf.nn.softmax(logits)\n",
        "\n",
        "        # 定义交叉熵损失函数\n",
        "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=ground_truth_input)\n",
        "        cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "        # 计算正确率\n",
        "        with tf.name_scope('evaluation'):\n",
        "            correct_prediction = tf.equal(\n",
        "                tf.argmax(final_tensor, 1), tf.argmax(ground_truth_input, 1))\n",
        "            evaluation_step = tf.reduce_mean(\n",
        "                tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # 训练过程\n",
        "    with tf.Session(graph=graph) as sess:\n",
        "        init = tf.global_variables_initializer().run()\n",
        "\n",
        "        # 模型和摘要的保存目录\n",
        "        import time\n",
        "        timestamp = str(int(time.time()))\n",
        "        out_dir = os.path.abspath(\n",
        "            os.path.join(os.path.curdir, 'runs', timestamp))\n",
        "        print('\\nWriting to {}\\n'.format(out_dir))\n",
        "        # 损失值和正确率的摘要\n",
        "        loss_summary = tf.summary.scalar('loss', cross_entropy_mean)\n",
        "        acc_summary = tf.summary.scalar('accuracy', evaluation_step)\n",
        "        # 训练摘要\n",
        "        train_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
        "        train_summary_dir = os.path.join(out_dir, 'summaries', 'train')\n",
        "        train_summary_writer = tf.summary.FileWriter(train_summary_dir,\n",
        "                                                     sess.graph)\n",
        "        # 开发摘要\n",
        "        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
        "        dev_summary_dir = os.path.join(out_dir, 'summaries', 'dev')\n",
        "        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
        "        # 保存检查点\n",
        "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, 'checkpoints'))\n",
        "        checkpoint_prefix = os.path.join(checkpoint_dir, 'model')\n",
        "        if not os.path.exists(checkpoint_dir):\n",
        "            os.makedirs(checkpoint_dir)\n",
        "            saver = tf.train.Saver(\n",
        "                tf.global_variables(), max_to_keep=num_checkpoints)\n",
        "\n",
        "        for i in range(steps):\n",
        "            if i > 500:\n",
        "                learning_rate = 0.001\n",
        "            else:\n",
        "                learning_rate = 0.01\n",
        "            # 每次获取一个batch的训练数据\n",
        "            train_bottlenecks, train_ground_truth = get_random_cached_bottlenecks(\n",
        "                sess, n_classes, image_lists, batch, 'training',\n",
        "                jpeg_data_tensor, bottleneck_tensor)\n",
        "            train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy_mean)\n",
        "            _, train_summaries = sess.run(\n",
        "                [train_step, train_summary_op],\n",
        "                feed_dict={\n",
        "                    bottleneck_input: train_bottlenecks,\n",
        "                    ground_truth_input: train_ground_truth\n",
        "                })\n",
        "\n",
        "            # 保存每步的摘要\n",
        "            train_summary_writer.add_summary(train_summaries, i)\n",
        "\n",
        "            # 在验证集上测试正确率\n",
        "            if i % 100 == 0 or i + 1 == steps:\n",
        "                validation_bottlenecks, validation_ground_truth = get_random_cached_bottlenecks(\n",
        "                    sess, n_classes, image_lists, batch, 'validation',\n",
        "                    jpeg_data_tensor, bottleneck_tensor)\n",
        "                validation_accuracy, dev_summaries = sess.run(\n",
        "                    [evaluation_step, dev_summary_op],\n",
        "                    feed_dict={\n",
        "                        bottleneck_input: validation_bottlenecks,\n",
        "                        ground_truth_input: validation_ground_truth\n",
        "                    })\n",
        "                print(\n",
        "                    'Step %d : Validation accuracy on random sampled %d examples = %.1f%%'\n",
        "                    % (i, batch, validation_accuracy * 100))\n",
        "\n",
        "            # 每隔checkpoint_every保存一次模型和测试摘要\n",
        "            if i % checkpoint_every == 0:\n",
        "                dev_summary_writer.add_summary(dev_summaries, i)\n",
        "                path = saver.save(sess, checkpoint_prefix, global_step=i)\n",
        "                print('Saved model checkpoint to {}\\n'.format(path))\n",
        "\n",
        "        # 最后在测试集上测试正确率\n",
        "        test_bottlenecks, test_ground_truth = get_test_bottlenecks(\n",
        "            sess, image_lists, n_classes, jpeg_data_tensor, bottleneck_tensor)\n",
        "        test_accuracy = sess.run(\n",
        "            evaluation_step,\n",
        "            feed_dict={\n",
        "                bottleneck_input: test_bottlenecks,\n",
        "                ground_truth_input: test_ground_truth\n",
        "            })\n",
        "        print('Final test accuracy = %.1f%%' % (test_accuracy * 100))\n",
        "\n",
        "        # 保存标签\n",
        "        output_labels = os.path.join(out_dir, 'labels.txt')\n",
        "        with tf.gfile.FastGFile(output_labels, 'w') as f:\n",
        "            keys = list(image_lists.keys())\n",
        "            for i in range(len(keys)):\n",
        "                keys[i] = '%2d -> %s' % (i, keys[i])\n",
        "            f.write('\\n'.join(keys) + '\\n')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Writing to /content/runs/1532426620\n",
            "\n",
            "Step 0 : Validation accuracy on random sampled 100 examples = 14.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-0\n",
            "\n",
            "Step 100 : Validation accuracy on random sampled 100 examples = 58.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-100\n",
            "\n",
            "Step 200 : Validation accuracy on random sampled 100 examples = 71.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-200\n",
            "\n",
            "Step 300 : Validation accuracy on random sampled 100 examples = 75.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-300\n",
            "\n",
            "Step 400 : Validation accuracy on random sampled 100 examples = 83.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-400\n",
            "\n",
            "Step 500 : Validation accuracy on random sampled 100 examples = 86.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-500\n",
            "\n",
            "Step 600 : Validation accuracy on random sampled 100 examples = 81.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-600\n",
            "\n",
            "Step 700 : Validation accuracy on random sampled 100 examples = 88.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-700\n",
            "\n",
            "Step 800 : Validation accuracy on random sampled 100 examples = 92.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-800\n",
            "\n",
            "Step 900 : Validation accuracy on random sampled 100 examples = 86.0%\n",
            "Saved model checkpoint to /content/runs/1532426620/checkpoints/model-900\n",
            "\n",
            "Step 999 : Validation accuracy on random sampled 100 examples = 85.0%\n",
            "Final test accuracy = 85.5%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lcQtFrSaVsmX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
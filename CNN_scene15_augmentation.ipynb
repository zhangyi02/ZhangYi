{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_scene15_augmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/zhangyi02/ZhangYi/blob/master/CNN_scene15_augmentation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "8Vb8nltYcO0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9d7e0e91-b8e2-41d3-bffc-3724e0f79ef9"
      },
      "cell_type": "code",
      "source": [
        "! wget http://www-cvr.ai.uiuc.edu/ponce_grp/data/scene_categories/scene_categories.zip\n",
        "import zipfile\n",
        "import os\n",
        "def un_zip():\n",
        "    \"\"\"unzip zip file\"\"\"\n",
        "    zip_file = zipfile.ZipFile(\"scene_categories.zip\")\n",
        "    if os.path.isdir(\"scene_categories\"):\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir(\"scene_categories\")\n",
        "    for names in zip_file.namelist():\n",
        "        zip_file.extract(names,\"scene_categories\")\n",
        "    zip_file.close()\n",
        "un_zip()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-24 01:31:57--  http://www-cvr.ai.uiuc.edu/ponce_grp/data/scene_categories/scene_categories.zip\n",
            "Resolving www-cvr.ai.uiuc.edu (www-cvr.ai.uiuc.edu)... 128.174.227.253\n",
            "Connecting to www-cvr.ai.uiuc.edu (www-cvr.ai.uiuc.edu)|128.174.227.253|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86098604 (82M) [application/zip]\n",
            "Saving to: ‘scene_categories.zip’\n",
            "\n",
            "scene_categories.zi 100%[===================>]  82.11M  32.7MB/s    in 2.5s    \n",
            "\n",
            "2018-07-24 01:31:59 (32.7 MB/s) - ‘scene_categories.zip’ saved [86098604/86098604]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zBcRSAg5cw9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "192387a1-1ef5-47e3-d76f-b6e6c3441aba"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1bAgMvEBo5ly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "\n",
        "def pre_processing():\n",
        "    img_name_list = {}\n",
        "    img_name_train_list = {}\n",
        "    img_name_test_list = {}\n",
        "    img_name_train_total = []\n",
        "    img_name_test_total = []\n",
        "    label_train_total = []\n",
        "    label_test_total = []\n",
        "    img_class = ['bedroom', 'CALsuburb', 'industrial', 'kitchen', 'livingroom',\n",
        "                 'MITcoast', 'MITforest', 'MIThighway', 'MITinsidecity', 'MITmountain',\n",
        "                 'MITopencountry', 'MITstreet', 'MITtallbuilding', 'PARoffice', 'store']\n",
        "    for i in range(len(img_class)):\n",
        "        path_class = 'scene_categories/' + img_class[i]\n",
        "        img_name_list[i] = os.listdir(path_class)  # 列出文件夹下所有的目录与文件\n",
        "\n",
        "        img_name_train_list[i] = random.sample(img_name_list[i], 100)\n",
        "        img_name_test_list[i] = list(set(img_name_list[i]) - set(img_name_train_list[i]))\n",
        "        #   至此读出了所有文件路径存储于img_train_list, img_test_list两个字典中，key为label的index，对应的为该类下所有图片\n",
        "\n",
        "        img_name_train_total += img_name_train_list[i]\n",
        "        label_train_total += [i] * len(img_name_train_list[i])\n",
        "        img_name_test_total += img_name_test_list[i]\n",
        "        label_test_total += [i] * len(img_name_test_list[i])\n",
        "    #   将各个label训练、测试数据分别合并为一个list\n",
        "\n",
        "    train_index = np.arange(len(img_name_train_total))\n",
        "    np.random.shuffle(train_index)\n",
        "    img_name_train_total_shuffle = [img_name_train_total[index] for index in train_index]\n",
        "    label_train_total_shuffle = [label_train_total[index] for index in train_index]\n",
        "    # shuffle 数据\n",
        "\n",
        "    batch_size = 50\n",
        "    batch_nums = len(img_name_train_total_shuffle) // batch_size\n",
        "    img_name_batch = {}\n",
        "    label_batch = {}\n",
        "    for batch_num in range(batch_nums):\n",
        "        img_name_batch[batch_num] = img_name_train_total_shuffle[batch_num * batch_size: (batch_num + 1) * batch_size]\n",
        "        label_batch[batch_num] = label_train_total_shuffle[batch_num * batch_size: (batch_num + 1) * batch_size]\n",
        "\n",
        "    return img_name_batch, label_batch, img_class, img_name_test_total, label_test_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "skwAi5ucdo8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d43e222a-4fa9-40f7-aef1-cc4062d45a3e"
      },
      "cell_type": "code",
      "source": [
        "# Create some wrappers for simplicity\n",
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    # MaxPool2D wrapper\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, 2, 2, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "\n",
        "# Create model\n",
        "def conv_net(x, weights, biases, dropout):\n",
        "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
        "    # Reshape to match picture format [Height x Width x Channel]\n",
        "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "    x = tf.reshape(x, shape=[-1, img_size, img_size, 1])\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    # Add Convolution layer _zy\n",
        "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
        "    # Max pooling (down-sampling)\n",
        "    conv3 = maxpool2d(conv3, k=2)\n",
        "    print(conv3.shape)\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv3 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    # Apply Dropout\n",
        "    fc1 = tf.nn.dropout(fc1, dropout)\n",
        "    \n",
        "    \n",
        "    fc2 = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
        "    fc2 = tf.nn.relu(fc2)\n",
        "    # Apply Dropout\n",
        "    fc2 = tf.nn.dropout(fc2, dropout)\n",
        "    \n",
        "    fc3 = tf.add(tf.matmul(fc2, weights['wd3']), biases['bd3'])\n",
        "    fc3 = tf.nn.relu(fc3)\n",
        "    # Apply Dropout\n",
        "    fc3 = tf.nn.dropout(fc3, dropout)\n",
        "\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc3, weights['out']), biases['out'])\n",
        "    return out\n",
        "\n",
        "def normlization():\n",
        "    img_data_max, img_data_min = 0, 0\n",
        "    for batch_num in range(len(img_name_batch)):\n",
        "        img_name = img_name_batch[batch_num]\n",
        "        label = label_batch[batch_num]\n",
        "        for i in range(len(img_name)):\n",
        "            img_full_name = 'scene_categories/' + img_class[label[i]] + '/' + img_name[i]\n",
        "            img = cv2.imread(img_full_name)[:, :, 0]\n",
        "            img = cv2.resize(img, (img_size+2, img_size+2))\n",
        "            img_data = np.reshape(img,(-1,))\n",
        "            if img_data_max < max(img_data):\n",
        "                img_data_max = max(img_data)\n",
        "            if img_data_min > min(img_data):\n",
        "                img_data_min = min(img_data)\n",
        "    return img_data_max, img_data_min\n",
        "\n",
        "\n",
        "def batch():\n",
        "    # read jpg\n",
        "    batch_num = np.random.randint(0, len(img_name_batch))\n",
        "    img_name = img_name_batch[batch_num]\n",
        "    label = label_batch[batch_num]\n",
        "    img_data = np.zeros((len(img_name)*9, img_size * img_size))\n",
        "    label2 = np.zeros((len(img_name)*9, len(img_class)))\n",
        "    for i in range(len(img_name)):\n",
        "        img_full_name = 'scene_categories/' + img_class[label[i]] + '/' + img_name[i]\n",
        "        img = cv2.imread(img_full_name)[:, :, 0]\n",
        "        img = cv2.resize(img, (img_size+2, img_size+2))\n",
        "        d = -1\n",
        "        for j in range(3):\n",
        "            for k in range(3):\n",
        "                d += 1\n",
        "                img_data_ = np.reshape(img[j:j+img_size, k:k+img_size],(-1,))\n",
        "#                 img_data_min = min(img_data_)\n",
        "#                 img_data_max = max(img_data_)\n",
        "                img_data_nor = (img_data_ - img_data_min) / (img_data_max - img_data_min)\n",
        "                img_data[i*9+d] = img_data_nor\n",
        "                label2[i*9+d, label[i]] = 1\n",
        "#                 img_ = scale(img[j:j+img_size, k:k+img_size])\n",
        "#                 img_data[i*9+d] = np.reshape(img_,(-1,))\n",
        "#                 label2[i*9+d, label[i]] = 1\n",
        "    return img_data, label2\n",
        "\n",
        "\n",
        "def batch_test():\n",
        "    # read jpg\n",
        "    img_name = img_name_test\n",
        "    label = label_test\n",
        "    img_data = np.zeros((len(img_name), img_size * img_size))\n",
        "    label2 = np.zeros((len(img_name), len(img_class)))\n",
        "    for i in range(len(img_name)):\n",
        "        img_full_name = 'scene_categories/' + img_class[label[i]] + '/' + img_name[i]\n",
        "        img = cv2.imread(img_full_name)[:, :, 0]\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        img_data_ = np.reshape(img,(-1,))\n",
        "#         img_data_min = min(img_data_)\n",
        "#         img_data_max = max(img_data_)\n",
        "        img_data_nor = (img_data_ - img_data_min) / (img_data_max - img_data_min)\n",
        "        img_data[i] = img_data_nor\n",
        "        label2[i, label[i]] = 1\n",
        "#         img = scale(img)\n",
        "#         img_data[i] = np.reshape(img, (-1,))\n",
        "#         label2[i, label[i]] = 1\n",
        "    return img_data, label2\n",
        "\n",
        "\n",
        "img_name_batch, label_batch, img_class, img_name_test, label_test = pre_processing()\n",
        "img_size = 64\n",
        "img_data_max, img_data_min = normlization()\n",
        "\n",
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "num_steps = 2000\n",
        "display_step = 100\n",
        "\n",
        "# Network Parameters\n",
        "num_input = img_size * img_size  # MNIST data input (img shape: 28*28)\n",
        "num_classes = 15  # MNIST total classes (0-9 digits)\n",
        "dropout = 0.5  # Dropout, probability to keep units\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(tf.float32, [None, num_input])\n",
        "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
        "keep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    # 5x5 conv, 1 input, 32 outputs\n",
        "    'wc1': tf.Variable(tf.random_normal([3, 3, 1, 64]) * np.sqrt(2/1/9)),\n",
        "    # 5x5 conv, 32 inputs, 64 outputs\n",
        "    'wc2': tf.Variable(tf.random_normal([3, 3, 64, 128]) * np.sqrt(2/64/9)),\n",
        "    # 5X5 conv, 64 inputs, 128 outputs\n",
        "    'wc3': tf.Variable(tf.random_normal([3, 3, 128, 256]) * np.sqrt(2/128/9)),\n",
        "    # fully connected, 8*8*128 inputs, 1024 outputs  ## decided by maxpooling k\n",
        "    'wd1': tf.Variable(tf.random_normal(\n",
        "        [int(img_size/8) * int(img_size/8) * 256, 512]) * np.sqrt(2/256/64)),\n",
        "    # fully connected, 1024 inputs, 512 outputs\n",
        "    'wd2': tf.Variable(tf.random_normal([512, 256]) * np.sqrt(2/512)),\n",
        "    'wd3': tf.Variable(tf.random_normal([256, 256]) * np.sqrt(2/256)),\n",
        "    # 512 inputs, 10 outputs (class prediction)\n",
        "    'out': tf.Variable(tf.random_normal([256, num_classes]) * np.sqrt(2/256))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.zeros([64])),\n",
        "    'bc2': tf.Variable(tf.zeros([128])),\n",
        "    'bc3': tf.Variable(tf.zeros([256])),\n",
        "    'bd1': tf.Variable(tf.zeros([512])),\n",
        "    'bd2': tf.Variable(tf.zeros([256])),\n",
        "    'bd3': tf.Variable(tf.zeros([256])),\n",
        "    'out': tf.Variable(tf.zeros([num_classes]))\n",
        "}\n",
        "\n",
        "# Construct model\n",
        "logits = conv_net(X, weights, biases, keep_prob)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Start training\n",
        "with tf.Session(config = config) as sess:\n",
        "    # Run the initializer\n",
        "    print('running cnn')\n",
        "    sess.run(init)\n",
        "    \n",
        "    for step in range(1, num_steps + 1):\n",
        "        if step > 1000:\n",
        "            learning_rate = 0.0005\n",
        "        # print('iter: ', step)\n",
        "        batch_x, batch_y = batch()\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.8})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
        "                                                                 Y: batch_y,\n",
        "                                                                 keep_prob: 1})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc) +'<br>')\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    test_x, test_y = batch_test()\n",
        "    print('Testing Accuracy:', \\\n",
        "          sess.run(accuracy, feed_dict={X: test_x,\n",
        "                                        Y: test_y,\n",
        "                                        keep_prob: 1.0}))\n",
        "    print('<br>learning rate = %.4f, img size = %i, dropout = %.3f' %(learning_rate, img_size, dropout))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 8, 8, 256)\n",
            "running cnn\n",
            "Step 1, Minibatch Loss= 194.9240, Training Accuracy= 0.100<br>\n",
            "Step 100, Minibatch Loss= 2.4974, Training Accuracy= 0.200<br>\n",
            "Step 200, Minibatch Loss= 2.3128, Training Accuracy= 0.304<br>\n",
            "Step 300, Minibatch Loss= 2.0077, Training Accuracy= 0.364<br>\n",
            "Step 400, Minibatch Loss= 2.0381, Training Accuracy= 0.316<br>\n",
            "Step 500, Minibatch Loss= 1.9727, Training Accuracy= 0.396<br>\n",
            "Step 600, Minibatch Loss= 1.7555, Training Accuracy= 0.496<br>\n",
            "Step 700, Minibatch Loss= 1.6250, Training Accuracy= 0.447<br>\n",
            "Step 800, Minibatch Loss= 1.5435, Training Accuracy= 0.507<br>\n",
            "Step 900, Minibatch Loss= 1.1101, Training Accuracy= 0.624<br>\n",
            "Step 1000, Minibatch Loss= 0.8418, Training Accuracy= 0.680<br>\n",
            "Step 1100, Minibatch Loss= 0.6153, Training Accuracy= 0.824<br>\n",
            "Step 1200, Minibatch Loss= 0.2503, Training Accuracy= 0.947<br>\n",
            "Step 1300, Minibatch Loss= 0.0684, Training Accuracy= 0.980<br>\n",
            "Step 1400, Minibatch Loss= 0.0519, Training Accuracy= 0.980<br>\n",
            "Step 1500, Minibatch Loss= 0.0147, Training Accuracy= 1.000<br>\n",
            "Step 1600, Minibatch Loss= 0.0020, Training Accuracy= 1.000<br>\n",
            "Step 1700, Minibatch Loss= 0.0043, Training Accuracy= 1.000<br>\n",
            "Step 1800, Minibatch Loss= 0.0025, Training Accuracy= 1.000<br>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RPKDN9IC2qgL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "w\\*1 seems doesn't work<br>"
      ]
    },
    {
      "metadata": {
        "id": "e9WI59gp4NEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1, Minibatch Loss= 9.1069, Training Accuracy= 0.080<br>\n",
        "Step 100, Minibatch Loss= 1.2083, Training Accuracy= 0.631<br>\n",
        "Step 200, Minibatch Loss= 0.4360, Training Accuracy= 0.900<br>\n",
        "Step 300, Minibatch Loss= 0.0265, Training Accuracy= 1.000<br>\n",
        "Step 400, Minibatch Loss= 0.0458, Training Accuracy= 0.984<br>\n",
        "Step 500, Minibatch Loss= 0.0001, Training Accuracy= 1.000<br>\n",
        "Step 600, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 700, Minibatch Loss= 0.0005, Training Accuracy= 1.000<br>\n",
        "Step 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000<br>\n",
        "Step 900, Minibatch Loss= 0.0005, Training Accuracy= 1.000<br>\n",
        "Step 1000, Minibatch Loss= 0.0001, Training Accuracy= 1.000<br>\n",
        "Step 1100, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1200, Minibatch Loss= 0.0010, Training Accuracy= 1.000<br>\n",
        "Step 1300, Minibatch Loss= 0.0001, Training Accuracy= 1.000<br>\n",
        "Step 1400, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1500, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1600, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1700, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1800, Minibatch Loss= 0.0001, Training Accuracy= 1.000<br>\n",
        "Step 1900, Minibatch Loss= 0.0052, Training Accuracy= 1.000<br>\n",
        "Step 2000, Minibatch Loss= 0.0001, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.5329983\n",
        "<br>learning rate = 0.001->0.005(1000step), img size = 64, dropout = 0.500<br>\n",
        "totally 0-1 normalization & augmentation = 9<br>\n",
        "w / np.sqrt(2/input_size); b = 0\n"
      ]
    },
    {
      "metadata": {
        "id": "zDh2wMM02B1i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1, Minibatch Loss= 50.6407, Training Accuracy= 0.140<br>\n",
        "Step 100, Minibatch Loss= 1.7829, Training Accuracy= 0.491<br>\n",
        "Step 200, Minibatch Loss= 0.6602, Training Accuracy= 0.811<br>\n",
        "Step 300, Minibatch Loss= 0.0527, Training Accuracy= 0.991<br>\n",
        "Step 400, Minibatch Loss= 0.0596, Training Accuracy= 0.978<br>\n",
        "Step 500, Minibatch Loss= 0.0009, Training Accuracy= 1.000<br>\n",
        "Step 600, Minibatch Loss= 0.0006, Training Accuracy= 1.000<br>\n",
        "Step 700, Minibatch Loss= 0.0002, Training Accuracy= 1.000<br>\n",
        "Step 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000<br>\n",
        "Step 900, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1000, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1100, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1200, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1300, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1400, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1500, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1600, Minibatch Loss= 0.0008, Training Accuracy= 1.000<br>\n",
        "Step 1700, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1800, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 1900, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Step 2000, Minibatch Loss= 0.0000, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.54237854\n",
        "<br>learning rate = 0.001->0.005(1000 step), img size = 64, dropout = 0.500<br>\n",
        "totally 0-1 normalization & augmentation = 9<br>\n",
        "w / np.sqrt(1/input_size); b = 0"
      ]
    },
    {
      "metadata": {
        "id": "dxtJvMeq-irk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1, Minibatch Loss= 102.5965, Training Accuracy= 0.080<br>\n",
        "Step 100, Minibatch Loss= 2.5593, Training Accuracy= 0.171<br>\n",
        "Step 200, Minibatch Loss= 2.2665, Training Accuracy= 0.329<br>\n",
        "Step 300, Minibatch Loss= 2.0441, Training Accuracy= 0.307<br>\n",
        "Step 400, Minibatch Loss= 1.6417, Training Accuracy= 0.489<br>\n",
        "Step 500, Minibatch Loss= 1.5321, Training Accuracy= 0.496<br>\n",
        "Step 600, Minibatch Loss= 1.5222, Training Accuracy= 0.549<br>\n",
        "Step 700, Minibatch Loss= 1.1719, Training Accuracy= 0.642<br>\n",
        "Step 800, Minibatch Loss= 0.9331, Training Accuracy= 0.749<br>\n",
        "Step 900, Minibatch Loss= 0.3650, Training Accuracy= 0.909<br>\n",
        "Step 1000, Minibatch Loss= 0.3061, Training Accuracy= 0.902<br>\n",
        "Step 1100, Minibatch Loss= 0.2839, Training Accuracy= 0.922<br>\n",
        "Step 1200, Minibatch Loss= 0.1120, Training Accuracy= 0.982<br>\n",
        "Step 1300, Minibatch Loss= 0.0315, Training Accuracy= 1.000<br>\n",
        "Step 1400, Minibatch Loss= 0.0296, Training Accuracy= 1.000<br>\n",
        "Step 1500, Minibatch Loss= 0.0148, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.46968174\n",
        "<br>learning rate = 0.0010, img size = 64, dropout = 0.500<br>\n",
        "totally 0-1 normalization & augmentation = 9<br>\n"
      ]
    },
    {
      "metadata": {
        "id": "4unEXZQB_AfC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1, Minibatch Loss= 272.6266, Training Accuracy= 0.060<br>\n",
        "Step 100, Minibatch Loss= 2.6149, Training Accuracy= 0.118<br>\n",
        "Step 200, Minibatch Loss= 2.3687, Training Accuracy= 0.300<br>\n",
        "Step 300, Minibatch Loss= 2.2466, Training Accuracy= 0.229<br>\n",
        "Step 400, Minibatch Loss= 2.2527, Training Accuracy= 0.260<br>\n",
        "Step 500, Minibatch Loss= 1.9124, Training Accuracy= 0.451<br>\n",
        "Step 600, Minibatch Loss= 1.7814, Training Accuracy= 0.404<br>\n",
        "Step 700, Minibatch Loss= 1.2468, Training Accuracy= 0.596<br>\n",
        "Step 800, Minibatch Loss= 0.5802, Training Accuracy= 0.860<br>\n",
        "Step 900, Minibatch Loss= 0.5665, Training Accuracy= 0.829<br>\n",
        "Step 1000, Minibatch Loss= 0.6768, Training Accuracy= 0.831<br>\n",
        "Step 1100, Minibatch Loss= 0.1627, Training Accuracy= 0.956<br>\n",
        "Step 1200, Minibatch Loss= 0.0648, Training Accuracy= 0.998<br>\n",
        "Step 1300, Minibatch Loss= 0.0248, Training Accuracy= 1.000<br>\n",
        "Step 1400, Minibatch Loss= 0.0053, Training Accuracy= 1.000<br>\n",
        "Step 1500, Minibatch Loss= 0.0018, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.4639866\n",
        "<br>learning rate = 0.0010, img size = 64, dropout = 0.500<br>\n",
        "batch 0-1 normalization & augmentation = 9"
      ]
    },
    {
      "metadata": {
        "id": "WAjGWPpk5QwJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1, Minibatch Loss= 3.3431, Training Accuracy= 0.100<br>\n",
        "Step 100, Minibatch Loss= 2.6898, Training Accuracy= 0.120<br>\n",
        "Step 200, Minibatch Loss= 2.5636, Training Accuracy= 0.120<br>\n",
        "Step 300, Minibatch Loss= 2.1833, Training Accuracy= 0.255<br>\n",
        "Step 400, Minibatch Loss= 1.8982, Training Accuracy= 0.320<br>\n",
        "Step 500, Minibatch Loss= 1.2663, Training Accuracy= 0.545<br>\n",
        "Step 600, Minibatch Loss= 1.0513, Training Accuracy= 0.630<br>\n",
        "Step 700, Minibatch Loss= 0.4957, Training Accuracy= 0.810<br>\n",
        "Step 800, Minibatch Loss= 0.3374, Training Accuracy= 0.870<br>\n",
        "Step 900, Minibatch Loss= 0.1788, Training Accuracy= 0.955<br>\n",
        "Step 1000, Minibatch Loss= 0.1225, Training Accuracy= 0.965<br>\n",
        "Step 1100, Minibatch Loss= 0.0578, Training Accuracy= 0.985<br>\n",
        "Step 1200, Minibatch Loss= 0.0166, Training Accuracy= 1.000<br>\n",
        "Step 1300, Minibatch Loss= 0.0099, Training Accuracy= 1.000<br>\n",
        "Step 1400, Minibatch Loss= 0.0051, Training Accuracy= 1.000<br>\n",
        "Step 1500, Minibatch Loss= 0.0043, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.44087103\n",
        "<br>learning rate = 0.0010, img size = 64, dropout = 0.500<br>\n",
        "0-score normalization & augmentation = 4"
      ]
    },
    {
      "metadata": {
        "id": "C4rBK-6C6QmG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1, Minibatch Loss= 3.2704, Training Accuracy= 0.140<br>\n",
        "Step 100, Minibatch Loss= 2.7297, Training Accuracy= 0.060<br>\n",
        "Step 200, Minibatch Loss= 2.7280, Training Accuracy= 0.020<br>\n",
        "Step 300, Minibatch Loss= 2.7162, Training Accuracy= 0.060<br>\n",
        "Step 400, Minibatch Loss= 2.5011, Training Accuracy= 0.180<br>\n",
        "Step 500, Minibatch Loss= 1.7072, Training Accuracy= 0.360<br>\n",
        "Step 600, Minibatch Loss= 1.3197, Training Accuracy= 0.630<br>\n",
        "Step 700, Minibatch Loss= 0.9435, Training Accuracy= 0.640<br>\n",
        "Step 800, Minibatch Loss= 0.6959, Training Accuracy= 0.760<br>\n",
        "Step 900, Minibatch Loss= 0.0725, Training Accuracy= 1.000<br>\n",
        "Step 1000, Minibatch Loss= 0.0783, Training Accuracy= 0.980<br>\n",
        "Step 1100, Minibatch Loss= 0.0936, Training Accuracy= 0.980<br>\n",
        "Step 1200, Minibatch Loss= 0.0287, Training Accuracy= 1.000<br>\n",
        "Step 1300, Minibatch Loss= 0.0080, Training Accuracy= 1.000<br>\n",
        "Step 1400, Minibatch Loss= 0.0542, Training Accuracy= 0.980<br>\n",
        "Step 1500, Minibatch Loss= 0.0072, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.41038525\n",
        "<br>learning rate = 0.0010, img size = 64, dropout = 0.500<br>\n",
        "3\\*conv:64,128,256<br>\n",
        "3\\*fc:512,256,256<br>\n",
        "augmentation = 2"
      ]
    },
    {
      "metadata": {
        "id": "b69pA_3-3CiL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1, Minibatch Loss= 3.2841, Training Accuracy= 0.100<br>\n",
        "Step 100, Minibatch Loss= 2.7871, Training Accuracy= 0.060<br>\n",
        "Step 200, Minibatch Loss= 2.3767, Training Accuracy= 0.200<br>\n",
        "Step 300, Minibatch Loss= 2.0556, Training Accuracy= 0.300<br>\n",
        "Step 400, Minibatch Loss= 1.8364, Training Accuracy= 0.300<br>\n",
        "Step 500, Minibatch Loss= 1.4076, Training Accuracy= 0.500<br>\n",
        "Step 600, Minibatch Loss= 1.0426, Training Accuracy= 0.640<br>\n",
        "Step 700, Minibatch Loss= 0.7521, Training Accuracy= 0.740<br>\n",
        "Step 800, Minibatch Loss= 0.4012, Training Accuracy= 0.880<br>\n",
        "Step 900, Minibatch Loss= 0.3591, Training Accuracy= 0.880<br>\n",
        "Step 1000, Minibatch Loss= 0.1403, Training Accuracy= 1.000<br>\n",
        "Step 1100, Minibatch Loss= 0.0560, Training Accuracy= 1.000<br>\n",
        "Step 1200, Minibatch Loss= 0.0284, Training Accuracy= 1.000<br>\n",
        "Step 1300, Minibatch Loss= 0.0063, Training Accuracy= 1.000<br>\n",
        "Step 1400, Minibatch Loss= 0.0109, Training Accuracy= 1.000<br>\n",
        "Step 1500, Minibatch Loss= 0.0078, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.4087102\n",
        "<br>learning rate = 0.0010, img size = 64, dropout = 0.500<br>\n",
        "3\\*conv:64,128,256<br>\n",
        "3\\*fc:512,256,256"
      ]
    },
    {
      "metadata": {
        "id": "-M4t4KUdgHAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "learning rate = 0.001; img size = 64; dropout = 0.5<br>\n",
        "Step 1, Minibatch Loss= 3.2927, Training Accuracy= 0.060<br>\n",
        "Step 100, Minibatch Loss= 2.7346, Training Accuracy= 0.040<br>\n",
        "Step 200, Minibatch Loss= 2.3892, Training Accuracy= 0.180<br>\n",
        "Step 300, Minibatch Loss= 2.2070, Training Accuracy= 0.280<br>\n",
        "Step 400, Minibatch Loss= 1.9254, Training Accuracy= 0.400<br>\n",
        "Step 500, Minibatch Loss= 1.1103, Training Accuracy= 0.660<br>\n",
        "Step 600, Minibatch Loss= 0.7725, Training Accuracy= 0.740<br>\n",
        "Step 700, Minibatch Loss= 1.0170, Training Accuracy= 0.620<br>\n",
        "Step 800, Minibatch Loss= 0.2346, Training Accuracy= 0.960<br>\n",
        "Step 900, Minibatch Loss= 0.1016, Training Accuracy= 0.980<br>\n",
        "Step 1000, Minibatch Loss= 0.0475, Training Accuracy= 0.980<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.35008374"
      ]
    },
    {
      "metadata": {
        "id": "buMg6rl3vcwr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "learning rate = 0.001000, img size = 64, dropout = 0.5<br>\n",
        "Step 1, Minibatch Loss= 2.7135, Training Accuracy= 0.100<br>\n",
        "Step 100, Minibatch Loss= 2.7063, Training Accuracy= 0.040<br>\n",
        "Step 200, Minibatch Loss= 2.7133, Training Accuracy= 0.040<br>\n",
        "Step 300, Minibatch Loss= 2.4252, Training Accuracy= 0.200<br>\n",
        "Step 400, Minibatch Loss= 2.0151, Training Accuracy= 0.280<br>\n",
        "Step 500, Minibatch Loss= 1.0233, Training Accuracy= 0.680<br>\n",
        "Step 600, Minibatch Loss= 0.5331, Training Accuracy= 0.860<br>\n",
        "Step 700, Minibatch Loss= 0.2126, Training Accuracy= 0.940<br>\n",
        "Step 800, Minibatch Loss= 0.0660, Training Accuracy= 0.980<br>\n",
        "Step 900, Minibatch Loss= 0.0105, Training Accuracy= 1.000<br>\n",
        "Step 1000, Minibatch Loss= 0.0058, Training Accuracy= 1.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.33366835<br>\n",
        "增大卷积层size\n"
      ]
    },
    {
      "metadata": {
        "id": "cWBZWm9xsmGY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "learning rate = 0.001; img size = 64; dropout = 0.875<br>\n",
        "Step 1, Minibatch Loss= 2.8193, Training Accuracy= 0.100<br>\n",
        "Step 100, Minibatch Loss= 2.7312, Training Accuracy= 0.060<br>\n",
        "Step 200, Minibatch Loss= 2.6937, Training Accuracy= 0.020<br>\n",
        "Step 300, Minibatch Loss= 2.2853, Training Accuracy= 0.220<br>\n",
        "Step 400, Minibatch Loss= 2.0213, Training Accuracy= 0.320<br>\n",
        "Step 500, Minibatch Loss= 1.7134, Training Accuracy= 0.420<br>\n",
        "Step 600, Minibatch Loss= 0.4333, Training Accuracy= 0.960<br>\n",
        "Step 700, Minibatch Loss= 0.4460, Training Accuracy= 0.880<br>\n",
        "Step 800, Minibatch Loss= 0.1178, Training Accuracy= 1.000<br>\n",
        "Step 900, Minibatch Loss= 0.1311, Training Accuracy= 0.980<br>\n",
        "Step 1000, Minibatch Loss= 0.0548, Training Accuracy= 0.980<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.31289783"
      ]
    },
    {
      "metadata": {
        "id": "N2lGlGi6hVZr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "with learning rate = 0.001<br>\n",
        "Step 1, Minibatch Loss= 1213625344.0000, Training Accuracy= 0.020<br>\n",
        "Step 100, Minibatch Loss= 43687400.0000, Training Accuracy= 0.510<br>\n",
        "Step 200, Minibatch Loss= 18261356.0000, Training Accuracy= 0.610<br>\n",
        "Step 300, Minibatch Loss= 7593531.5000, Training Accuracy= 0.730<br>\n",
        "Step 400, Minibatch Loss= 3516608.7500, Training Accuracy= 0.780<br>\n",
        "Step 500, Minibatch Loss= 386.9200, Training Accuracy= 0.990<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.26599666"
      ]
    },
    {
      "metadata": {
        "id": "VDvUgxWmfe-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "learning rate 0.001<br>\n",
        "Step 1, Minibatch Loss= 11922490.0000, Training Accuracy= 0.050<br>\n",
        "Step 100, Minibatch Loss= 1126417.1250, Training Accuracy= 0.150<br>\n",
        "Step 200, Minibatch Loss= 901864.8750, Training Accuracy= 0.150<br>\n",
        "Step 300, Minibatch Loss= 619173.6250, Training Accuracy= 0.100<br>\n",
        "Step 400, Minibatch Loss= 469205.9062, Training Accuracy= 0.200<br>\n",
        "Step 500, Minibatch Loss= 420558.8438, Training Accuracy= 0.100<br>\n",
        "Step 600, Minibatch Loss= 220658.9688, Training Accuracy= 0.150<br>\n",
        "Step 700, Minibatch Loss= 178520.2188, Training Accuracy= 0.150<br>\n",
        "Step 800, Minibatch Loss= 146223.2812, Training Accuracy= 0.200<br>\n",
        "Step 900, Minibatch Loss= 78263.0156, Training Accuracy= 0.100<br>\n",
        "Step 1000, Minibatch Loss= 15069.7920, Training Accuracy= 0.150<br>\n",
        "Step 1100, Minibatch Loss= 19763.5781, Training Accuracy= 0.150<br>\n",
        "Step 1200, Minibatch Loss= 5730.0762, Training Accuracy= 0.100<br>\n",
        "Step 1300, Minibatch Loss= 3.1026, Training Accuracy= 0.100<br>\n",
        "Step 1400, Minibatch Loss= 1577.2947, Training Accuracy= 0.050<br>\n",
        "Step 1500, Minibatch Loss= 3.5202, Training Accuracy= 0.000<br>\n",
        "Step 1600, Minibatch Loss= 2.7354, Training Accuracy= 0.100<br>\n",
        "Step 1700, Minibatch Loss= 3.0511, Training Accuracy= 0.050<br>\n",
        "Step 1800, Minibatch Loss= 3.0807, Training Accuracy= 0.000<br>\n",
        "Step 1900, Minibatch Loss= 2.8522, Training Accuracy= 0.000<br>\n",
        "Step 2000, Minibatch Loss= 2.8605, Training Accuracy= 0.000<br>\n",
        "Optimization Finished!\n",
        "Testing Accuracy: 0.07638191"
      ]
    }
  ]
}